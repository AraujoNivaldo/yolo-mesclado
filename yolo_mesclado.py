# -*- coding: utf-8 -*-
"""TCC_Mesclado.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1toa-vX9hc7Jveh7KZJiFjhe6QrhupXOp
"""

!pip install opencv-contrib-python==4.4.0.40 --force-reinstall

import cv2
cv2.__version__

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Baixa o repositório da Darknet:
# %cd "content/"

!git clone https://github.com/AlexeyAB/darknet

# Configura o MAKEFILE para o uso do CUDA (DEPENDE DE GPGPU):
# %cd darknet
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile

# Verifica o CUDA:
!/usr/local/cuda/bin/nvcc --version

# Instala a Darknet:
!make

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/IC_YOLO_MESCLADO/treinamento"

! /content/darknet/darknet detector train data/directives.data model.cfg backup/model_last.weights -dont_show -map

# Commented out IPython magic to ensure Python compatibility.
from os import path, getcwd, chdir, listdir
import cv2
from numpy import argmax

# %cd "/content/drive/MyDrive/IC_YOLO_MESCLADO/ativacao"

# Carrega a lista de imagens no path de ativação:
image_files = []
chdir(path.join("input"))
for filename in listdir(getcwd()):
    if filename.endswith(".jpg"):
        image_files.append(filename)
chdir("..")

# Carrega a rede neural convolucional e sua arquitetura:
net = cv2.dnn.readNet("networks/model.weights", "networks/model.cfg")

# Carrega as classes:
classes = []
with open("networks/model.names", 'r') as f:
    classes = f.read().splitlines()

# Executa a ativação em todo arquivo JPG dentro do path de ativação:
for image in image_files:
    # Carrega a imagem:
    img = cv2.imread("input/" + image)

    # Váriaveis e ponteiros de execução:
    height, width, _ = img.shape

    net.setInput(cv2.dnn.blobFromImage(img, (1 / 255), (415, 416), (0, 0, 0), swapRB=True, crop=False))
    boxes = []
    confidences = []
    class_ids = []

    # Detecção e armazenamento das instâncias dos objetos:
    for output in net.forward(net.getUnconnectedOutLayersNames()):
        for detection in output:
            scores = detection[5:]
            class_id = argmax(scores)
            confidence = scores[class_id]
            if (confidence > 0.5):
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - (w / 2))
                y = int(center_y - (h / 2))
                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Desenha os retângulos, as classes e a taxa de confiança nos quadros:
    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)
    if (len(indexes) > 0):
        for i in indexes.flatten():
            x, y, w, h = boxes[i]
            label = str(classes[class_ids[i]])
            confidence = str(round(confidences[i], 2))
            cv2.rectangle(img, (x, y), ((x + w), (y + h)), (0, 255, 0), 2)
            cv2.putText(img, (label + ' ' + confidence), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 255), 1, cv2.LINE_4)

    # Salva a imagem de saída:
    cv2.imwrite(("output/" + image), img)